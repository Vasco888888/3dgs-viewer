{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c362f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Environment Setup\n",
    "\n",
    "# First, we upgrade pip to ensure it can handle complex dependency resolution\n",
    "#   without conflict errors (common in colab/kaggle environments).\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# Installing Pytorch (The Deep Learning Engine):\n",
    "#   We strictly pin Torch 2.4.0 + CUDA 11.8 to ensure compatibility with Nerfstudio.\n",
    "#   --index-url: Tells pip to download the specific GPU-enabled wheels \n",
    "#   directly from PyTorch, rather than the standard CPU versions found on PyPI.\n",
    "#   Without this, the code would run on the CPU (taking days).\n",
    "!pip install torch==2.4.0+cu118 torchvision==0.19.0+cu118 --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Installing Nerfstudio:\n",
    "#   Installs the main framework along with compiled \n",
    "#   CUDA extensions (like gsplat) required for rendering Gaussian Splats.\n",
    "!pip install nerfstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bfea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Input Preparation\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Kaggle mounts uploaded datasets in \"/kaggle/input\", which is a READ-ONLY directory.\n",
    "#   We need to find the video and move it to \"/kaggle/working\" (WRITEABLE) so we can \n",
    "#   process it without permission errors.\n",
    "search_path = \"/kaggle/input\"\n",
    "found_video = None\n",
    "\n",
    "# We use os.walk() to look through all folders in the input directory.\n",
    "#   It works regardless of what the user named their video file or which subfolder it's in.\n",
    "for root, dirs, files in os.walk(search_path):\n",
    "    for file in files:\n",
    "        # Check for common video container formats\n",
    "        if file.lower().endswith(('.mp4', '.mov', '.avi', '.mkv')):\n",
    "            found_video = os.path.join(root, file)\n",
    "            break\n",
    "    if found_video:\n",
    "        break\n",
    "\n",
    "# We copy and rename the file to \"input_video.mp4\".\n",
    "if found_video:\n",
    "    destination = \"/kaggle/working/input_video.mp4\"\n",
    "    shutil.copy(found_video, destination)\n",
    "    print(f\"Video copied to: {destination}\")\n",
    "else:\n",
    "    print(\"No video found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Preprocesing (Structure-from-Motion)\n",
    "\n",
    "# COLMAP: The engine for Structure-from-Motion (calculates camera poses).\n",
    "# FFmpeg: Required to extract individual frames from the input video file.\n",
    "# Xvfb (X Virtual Framebuffer): Essential for \"headless\" cloud environments like Kaggle.\n",
    "# It simulates a monitor so COLMAP's GUI-based features don't crash the session.\n",
    "!apt-get update && apt-get install -y colmap ffmpeg xvfb\n",
    "\n",
    "# 1. FFmpeg slices video -> images.\n",
    "# 2. COLMAP extracts features (SIFT) and matches them across frames.\n",
    "# 3. COLMAP calculates the sparse 3D point cloud and camera intrinsics/extrinsics.\n",
    "\n",
    "# xvfb-run: Wraps the command in a virtual display server to prevent \"no display\" errors.\n",
    "# ns-process-data: Nerfstudio's wrapper to turn raw video into training data.\n",
    "# --colmap-model-path colmap: Ensures it points to the installed binary\n",
    "# --gpu: forces feature (SIFT) extraction to run on the T4 GPU (10x faster than CPU).\n",
    "!xvfb-run -a -s \"-screen 0 1024x768x24\" ns-process-data video \\ \n",
    "    --data /kaggle/working/input_video.mp4 \\\n",
    "    --output-dir processed_data \\\n",
    "    --colmap-model-path colmap \\ \n",
    "    --gpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c11f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Gaussian Splatting Model Training\n",
    "\n",
    "# MAX_JOBS=5: Forces the system to use fewer parallel workers\n",
    "#   for Kaggle to prevent crashing the 30GB RAM limit during dataloading.\n",
    "\n",
    "# We use 'splatfacto', Nerfstudio's implementation of 3D Gaussian Splatting.\n",
    "\n",
    "# --vis tensorboard: Logs training metrics (Loss, PSNR) to TensorBoard instead of \n",
    "#   launching the interactive viewer. Best for headless cloud environments.\n",
    "\n",
    "# --max-num-iterations 15000: A balance between quality and speed.\n",
    "\n",
    "# --pipeline.model.cull_alpha_thresh 0.01: Aggressively deletes points that are \n",
    "#   almost transparent (alpha < 1%). This reduces file size and removes \"haze\".\n",
    "\n",
    "# --pipeline.model.stop_split_at 10000: Stops densifying (adding new points) \n",
    "#   after step 10k. The final 5k steps focus only on refining colors/positions.\n",
    "#   This prevents the file size from exploding with unnecessary noise.\n",
    "\n",
    "# --viewer.quit-on-train-completion True:\n",
    "#    Tells the process to automatically shut down after 15,000 steps. \n",
    "!export MAX_JOBS=5 && ns-train splatfacto --data processed_data \\\n",
    "    --vis tensorboard \\\n",
    "    --max-num-iterations 15000 \\\n",
    "    --pipeline.model.cull_alpha_thresh 0.01 \\\n",
    "    --pipeline.model.stop_split_at 10000 \\\n",
    "    --viewer.quit-on-train-completion True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5165f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 - Export and Convert Model\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# After training, Nerfstudio saves the model checkpoint and config file\n",
    "#   in a timestamped folder inside \"outputs/\". We need to find it to export.\n",
    "config_files = glob.glob(\"outputs/processed_data/splatfacto/*/config.yml\")\n",
    "\n",
    "if not config_files:\n",
    "    print(\"No config file found.\")\n",
    "else:\n",
    "    # If multiple training runs exist, we pick the latest one (alphabetically last).\n",
    "    latest_config = sorted(config_files)[-1]\n",
    "\n",
    "    # ns-export gaussian-splat: Converts Nerfstudio's internal checkpoint format\n",
    "    #   into a standard .ply (Polygon File Format) point cloud.\n",
    "    !ns-export gaussian-splat --load-config {latest_config} --output-dir exports/splat\n",
    "\n",
    "    # The raw .ply format is too heavy for standard web loading.\n",
    "    #   We use antimatter15's convert.py script to transform the .ply into\n",
    "    #   a .splat file, which is optimized for real-time WebGL rendering\n",
    "    #   inside our application (via React-Three-Fiber / Splat library).\n",
    "    if not os.path.exists(\"convert.py\"):\n",
    "        !wget -q https://raw.githubusercontent.com/antimatter15/splat/main/convert.py\n",
    "\n",
    "    input_ply = \"exports/splat/splat.ply\"\n",
    "\n",
    "    if os.path.exists(input_ply):\n",
    "        \n",
    "        # The convert.py script only takes the input file as an argument.\n",
    "        #   It automatically appends \".splat\" to create the output filename.\n",
    "        !python convert.py {input_ply}\n",
    "        \n",
    "        generated_auto_name = \"output.splat\"\n",
    "        final_destination = \"/kaggle/working/scene.splat\"\n",
    "        \n",
    "        # Move the generated file to the working directory root for easy download.\n",
    "        if os.path.exists(generated_auto_name):\n",
    "            if os.path.exists(final_destination):\n",
    "                os.remove(final_destination)\n",
    "            \n",
    "            shutil.move(generated_auto_name, final_destination)\n",
    "            print(f\"File created: {final_destination}\")\n",
    "        else:\n",
    "            print(f\"Expected file '{generated_auto_name}' is missing.\")\n",
    "            \n",
    "    else:\n",
    "        print(\"PLY file not found.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
